{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f9414ce3-ed1d-0ea9-903b-5d101fca67d7"
   },
   "source": [
    "# Summarizing Text with Amazon Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "94ea895e-16a0-6db5-005f-d07d132b06e6"
   },
   "source": [
    "Dataset used: [Kaggle.](https://www.kaggle.com/snap/amazon-fine-food-reviews)\n",
    "\n",
    "References that helped in implementing this algorithm:\n",
    "[Jaemin Cho's tutorial](https://github.com/j-min/tf_tutorial_plus/tree/master/RNN_seq2seq/contrib_seq2seq) \n",
    "Xin Pan's and Peter Liu's [GitHub page](https://github.com/tensorflow/models/tree/master/textsum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "3aee62b9-47ce-e416-5816-8df7126fe690",
    "execution": {
     "iopub.execute_input": "2022-01-09T07:39:53.396521Z",
     "iopub.status.busy": "2022-01-09T07:39:53.396261Z",
     "iopub.status.idle": "2022-01-09T07:39:53.401856Z",
     "shell.execute_reply": "2022-01-09T07:39:53.400901Z",
     "shell.execute_reply.started": "2022-01-09T07:39:53.396493Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T07:39:57.073243Z",
     "iopub.status.busy": "2022-01-09T07:39:57.072943Z",
     "iopub.status.idle": "2022-01-09T07:39:57.763538Z",
     "shell.execute_reply": "2022-01-09T07:39:57.762738Z",
     "shell.execute_reply.started": "2022-01-09T07:39:57.073211Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras.layers import Concatenate\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, TimeDistributed, LSTM, Embedding, Input\n",
    "from keras import Model\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1d14c9a8-f489-0f75-1627-bb43b5e811f1"
   },
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are taking only first 5000 rows of data because of computational limitations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "d53ed012-578f-5396-cf65-d5c959a6ae70",
    "execution": {
     "iopub.execute_input": "2022-01-09T07:40:35.792724Z",
     "iopub.status.busy": "2022-01-09T07:40:35.792445Z",
     "iopub.status.idle": "2022-01-09T07:40:40.186162Z",
     "shell.execute_reply": "2022-01-09T07:40:40.185164Z",
     "shell.execute_reply.started": "2022-01-09T07:40:35.792696Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"../input/Reviews.csv\")[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T07:40:40.188031Z",
     "iopub.status.busy": "2022-01-09T07:40:40.187768Z",
     "iopub.status.idle": "2022-01-09T07:40:40.195724Z",
     "shell.execute_reply": "2022-01-09T07:40:40.195128Z",
     "shell.execute_reply.started": "2022-01-09T07:40:40.187998Z"
    }
   },
   "outputs": [],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "233f6106-38e4-37eb-bb57-6add8f708926",
    "execution": {
     "iopub.execute_input": "2022-01-09T07:40:40.197309Z",
     "iopub.status.busy": "2022-01-09T07:40:40.196913Z",
     "iopub.status.idle": "2022-01-09T07:40:40.208324Z",
     "shell.execute_reply": "2022-01-09T07:40:40.207628Z",
     "shell.execute_reply.started": "2022-01-09T07:40:40.197279Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "dbdc200c-e1a6-9759-f76a-56cc523f0d60",
    "execution": {
     "iopub.execute_input": "2022-01-09T07:40:40.526276Z",
     "iopub.status.busy": "2022-01-09T07:40:40.525827Z",
     "iopub.status.idle": "2022-01-09T07:40:40.550689Z",
     "shell.execute_reply": "2022-01-09T07:40:40.550108Z",
     "shell.execute_reply.started": "2022-01-09T07:40:40.526236Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "428bc803-5495-be4c-c373-baa73ddae461",
    "execution": {
     "iopub.execute_input": "2022-01-09T07:40:44.458888Z",
     "iopub.status.busy": "2022-01-09T07:40:44.457719Z",
     "iopub.status.idle": "2022-01-09T07:40:44.473663Z",
     "shell.execute_reply": "2022-01-09T07:40:44.472692Z",
     "shell.execute_reply.started": "2022-01-09T07:40:44.458826Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for any nulls values\n",
    "reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "53b96b64-e735-9a94-4a55-3e0b101ba64d",
    "execution": {
     "iopub.execute_input": "2022-01-09T07:40:49.664261Z",
     "iopub.status.busy": "2022-01-09T07:40:49.663519Z",
     "iopub.status.idle": "2022-01-09T07:40:49.686841Z",
     "shell.execute_reply": "2022-01-09T07:40:49.685744Z",
     "shell.execute_reply.started": "2022-01-09T07:40:49.664220Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove null values and unneeded features\n",
    "reviews = reviews.dropna()\n",
    "reviews = reviews.drop(['Id','ProductId','UserId','ProfileName','HelpfulnessNumerator','HelpfulnessDenominator',\n",
    "                        'Score','Time'], 1)\n",
    "reviews = reviews.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "a019e41d-e714-de1c-b5d0-9b6e11de4510",
    "execution": {
     "iopub.execute_input": "2022-01-09T07:40:56.540108Z",
     "iopub.status.busy": "2022-01-09T07:40:56.539816Z",
     "iopub.status.idle": "2022-01-09T07:40:56.551985Z",
     "shell.execute_reply": "2022-01-09T07:40:56.551107Z",
     "shell.execute_reply.started": "2022-01-09T07:40:56.540070Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T07:41:00.957208Z",
     "iopub.status.busy": "2022-01-09T07:41:00.956890Z",
     "iopub.status.idle": "2022-01-09T07:41:00.967218Z",
     "shell.execute_reply": "2022-01-09T07:41:00.966369Z",
     "shell.execute_reply.started": "2022-01-09T07:41:00.957176Z"
    }
   },
   "outputs": [],
   "source": [
    "data = reviews\n",
    "data.columns = ['headlines','text']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "654175ff-07c7-455d-1b8f-d702cee211c4",
    "execution": {
     "iopub.execute_input": "2022-01-09T07:41:05.000999Z",
     "iopub.status.busy": "2022-01-09T07:41:05.000728Z",
     "iopub.status.idle": "2022-01-09T07:41:05.012659Z",
     "shell.execute_reply": "2022-01-09T07:41:05.011778Z",
     "shell.execute_reply.started": "2022-01-09T07:41:05.000970Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inspecting some of the reviews\n",
    "for i in range(5):\n",
    "    print(\"Review #\",i+1)\n",
    "    print(data.headlines[i])\n",
    "    print(data.text[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T07:41:09.360641Z",
     "iopub.status.busy": "2022-01-09T07:41:09.360207Z",
     "iopub.status.idle": "2022-01-09T07:41:09.376278Z",
     "shell.execute_reply": "2022-01-09T07:41:09.375130Z",
     "shell.execute_reply.started": "2022-01-09T07:41:09.360608Z"
    }
   },
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T07:41:21.749619Z",
     "iopub.status.busy": "2022-01-09T07:41:21.749307Z",
     "iopub.status.idle": "2022-01-09T07:41:22.306678Z",
     "shell.execute_reply": "2022-01-09T07:41:22.304888Z",
     "shell.execute_reply.started": "2022-01-09T07:41:21.749568Z"
    }
   },
   "outputs": [],
   "source": [
    "StopWords = set(stopwords.words('english'))\n",
    "def preprocess(text):\n",
    "    new_text = text.lower() #Lowercasing text.\n",
    "    new_text = re.sub(r'\\([^)]*\\)', '', new_text) #Removing punctuations and special characters.\n",
    "    new_text = re.sub('\"','', new_text) #Removing double quotes.\n",
    "    new_text = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in new_text.split(\" \")]) #Replacing contractions.   \n",
    "    new_text = re.sub(r\"'s\\b\",\"\",new_text) #Eliminating apostrophe.\n",
    "    new_text = re.sub(\"[^a-zA-Z]\", \" \", new_text) #Removing non-alphabetical characters\n",
    "    new_text = ' '.join([word for word in new_text.split() if word not in StopWords]) #Removing stopwords.\n",
    "    new_text = ' '.join([word for word in new_text.split() if len(word) >= 3]) #Removing very short words\n",
    "    return new_text\n",
    "\n",
    "#Apply above preprocessing to both text and summary separately.\n",
    "text_cleaned = []\n",
    "summ_cleaned = []\n",
    "for text in data['text']:\n",
    "    text_cleaned.append(preprocess(text))\n",
    "for summary in data['headlines']:\n",
    "    summ_cleaned.append(preprocess(summary))\n",
    "clean_df = pd.DataFrame()\n",
    "clean_df['text'] = text_cleaned\n",
    "clean_df['headline'] = summ_cleaned\n",
    "\n",
    "#Replacing empty string summaries with nan values and then dropping those datapoints.\n",
    "clean_df['headline'].replace('', np.nan, inplace=True)\n",
    "clean_df.dropna(axis=0, inplace=True)\n",
    "\n",
    "#Adding START and END tokens to summaries for later use.\n",
    "clean_df['headline'] = clean_df['headline'].apply(lambda x: '<START>' + ' '+ x + ' '+ '<END>')\n",
    "for i in range(10):\n",
    "    print('News: ', clean_df['text'][i])\n",
    "    print('Headline:', clean_df['headline'][i])\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T07:41:34.649339Z",
     "iopub.status.busy": "2022-01-09T07:41:34.649029Z",
     "iopub.status.idle": "2022-01-09T07:41:34.672416Z",
     "shell.execute_reply": "2022-01-09T07:41:34.671636Z",
     "shell.execute_reply.started": "2022-01-09T07:41:34.649307Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get max length of texts and summaries.\n",
    "max_len_news = max([len(text.split()) for text in clean_df['text']])\n",
    "max_len_headline = max([len(text.split()) for text in clean_df['headline']])\n",
    "print(max_len_news, max_len_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T07:42:13.460902Z",
     "iopub.status.busy": "2022-01-09T07:42:13.460092Z",
     "iopub.status.idle": "2022-01-09T07:42:13.465222Z",
     "shell.execute_reply": "2022-01-09T07:42:13.464192Z",
     "shell.execute_reply.started": "2022-01-09T07:42:13.460860Z"
    }
   },
   "outputs": [],
   "source": [
    "# we will use lesser max_len_news for faster results and less computation usage :(\n",
    "max_len_news = 200\n",
    "max_len_headline = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T07:42:24.434184Z",
     "iopub.status.busy": "2022-01-09T07:42:24.433254Z",
     "iopub.status.idle": "2022-01-09T07:42:24.939489Z",
     "shell.execute_reply": "2022-01-09T07:42:24.938435Z",
     "shell.execute_reply.started": "2022-01-09T07:42:24.434134Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(clean_df['text'], clean_df['headline'], test_size=0.2, random_state=0)\n",
    "\n",
    "#Keras tokenizer for news text.\n",
    "news_tokenizer = Tokenizer()\n",
    "news_tokenizer.fit_on_texts(list(X_train))\n",
    "x_train_seq = news_tokenizer.texts_to_sequences(X_train)\n",
    "x_test_seq = news_tokenizer.texts_to_sequences(X_test)\n",
    "x_train_pad = pad_sequences(x_train_seq, maxlen=max_len_news, padding='post') #Post padding short texts with 0s.\n",
    "x_test_pad = pad_sequences(x_test_seq, maxlen=max_len_news, padding='post')\n",
    "#Vocab size of texts.\n",
    "news_vocab = len(news_tokenizer.word_index) + 1\n",
    "\n",
    "#Keras Tokenizer for summaries.\n",
    "headline_tokenizer = Tokenizer()\n",
    "headline_tokenizer.fit_on_texts(list(y_train))\n",
    "y_train_seq = headline_tokenizer.texts_to_sequences(y_train)\n",
    "y_test_seq = headline_tokenizer.texts_to_sequences(y_test)\n",
    "y_train_pad = pad_sequences(y_train_seq, maxlen=max_len_headline, padding='post')\n",
    "y_test_pad = pad_sequences(y_test_seq, maxlen=max_len_headline, padding='post')\n",
    "#Vocab size of summaries.\n",
    "headline_vocab = len(headline_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T07:42:39.091954Z",
     "iopub.status.busy": "2022-01-09T07:42:39.091534Z",
     "iopub.status.idle": "2022-01-09T07:42:39.116528Z",
     "shell.execute_reply": "2022-01-09T07:42:39.115577Z",
     "shell.execute_reply.started": "2022-01-09T07:42:39.091922Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttentionLayer(Layer):\n",
    "\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
    "            if verbose:\n",
    "                print('wa.s>',W_a_dot_s.shape)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>',U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        def create_inital_state(inputs, hidden_size):\n",
    "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
    "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
    "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
    "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
    "            return fake_state\n",
    "\n",
    "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
    "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T07:42:53.041667Z",
     "iopub.status.busy": "2022-01-09T07:42:53.041027Z",
     "iopub.status.idle": "2022-01-09T07:42:54.402663Z",
     "shell.execute_reply": "2022-01-09T07:42:54.402026Z",
     "shell.execute_reply.started": "2022-01-09T07:42:53.041633Z"
    }
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "embedding_dim = 500 #Size of word embeddings.\n",
    "latent_dim = 256 #No. of neurons in LSTM layer.\n",
    "\n",
    "encoder_input = Input(shape=(max_len_news, ))\n",
    "encoder_emb = Embedding(news_vocab, embedding_dim, trainable=True)(encoder_input) #Embedding Layer\n",
    "\n",
    "#Three-stacked LSTM layers for encoder. Return_state returns the activation state vectors, a(t) and c(t), return_sequences return the output of the neurons y(t).\n",
    "#With layers stacked one above the other, y(t) of previous layer becomes x(t) of next layer.\n",
    "encoder_lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.3, recurrent_dropout=0.2)\n",
    "y_1, a_1, c_1 = encoder_lstm1(encoder_emb)\n",
    "\n",
    "encoder_lstm2 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.3, recurrent_dropout=0.2)\n",
    "y_2, a_2, c_2 = encoder_lstm2(y_1)\n",
    "\n",
    "encoder_lstm3 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.3, recurrent_dropout=0.2)\n",
    "encoder_output, a_enc, c_enc = encoder_lstm3(y_2)\n",
    "\n",
    "#Single LSTM layer for decoder followed by Dense softmax layer to predict the next word in summary.\n",
    "decoder_input = Input(shape=(None,))\n",
    "decoder_emb = Embedding(headline_vocab, embedding_dim, trainable=True)(decoder_input)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.3, recurrent_dropout=0.2)\n",
    "decoder_output, decoder_fwd, decoder_back = decoder_lstm(decoder_emb, initial_state=[a_enc, c_enc]) #Final output states of encoder last layer are fed into decoder.\n",
    "\n",
    "#Attention Layer\n",
    "attn_layer = AttentionLayer(name='attention_layer') \n",
    "attn_out, attn_states = attn_layer([encoder_output, decoder_output]) \n",
    "\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_output, attn_out])\n",
    "\n",
    "decoder_dense = TimeDistributed(Dense(headline_vocab, activation='softmax'))\n",
    "decoder_output = decoder_dense(decoder_concat_input)\n",
    "\n",
    "model = Model([encoder_input, decoder_input], decoder_output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T07:42:58.928518Z",
     "iopub.status.busy": "2022-01-09T07:42:58.928130Z",
     "iopub.status.idle": "2022-01-09T11:15:54.938674Z",
     "shell.execute_reply": "2022-01-09T11:15:54.936115Z",
     "shell.execute_reply.started": "2022-01-09T07:42:58.928488Z"
    }
   },
   "outputs": [],
   "source": [
    "#Training the model with Early Stopping callback on val_loss.\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "# callback = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "history=model.fit([x_train_pad,y_train_pad[:,:-1]], y_train_pad.reshape(y_train_pad.shape[0],y_train_pad.shape[1], 1)[:,1:] ,epochs=150,\n",
    "                  batch_size=8, validation_data=([x_test_pad,y_test_pad[:,:-1]], y_test_pad.reshape(y_test_pad.shape[0],y_test_pad.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T11:17:55.302892Z",
     "iopub.status.busy": "2022-01-09T11:17:55.302412Z",
     "iopub.status.idle": "2022-01-09T11:17:55.539317Z",
     "shell.execute_reply": "2022-01-09T11:17:55.538422Z",
     "shell.execute_reply.started": "2022-01-09T11:17:55.302839Z"
    }
   },
   "outputs": [],
   "source": [
    "#Encoder inference model with trained inputs and outputs.\n",
    "encoder_model = Model(inputs=encoder_input, outputs=[encoder_output, a_enc, c_enc])\n",
    "\n",
    "#Initialising state vectors for decoder.\n",
    "decoder_initial_state_a = Input(shape=(latent_dim,))\n",
    "decoder_initial_state_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state = Input(shape=(max_len_news, latent_dim))\n",
    "\n",
    "#Decoder inference model\n",
    "decoder_out, decoder_a, decoder_c = decoder_lstm(decoder_emb, initial_state=[decoder_initial_state_a, decoder_initial_state_c])\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state, decoder_out])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_out, attn_out_inf])\n",
    "\n",
    "decoder_final = decoder_dense(decoder_inf_concat)\n",
    "decoder_model = Model([decoder_input]+[decoder_hidden_state, decoder_initial_state_a, decoder_initial_state_c], [decoder_final]+[decoder_a, decoder_c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T11:17:56.836332Z",
     "iopub.status.busy": "2022-01-09T11:17:56.836004Z",
     "iopub.status.idle": "2022-01-09T11:17:56.847655Z",
     "shell.execute_reply": "2022-01-09T11:17:56.847041Z",
     "shell.execute_reply.started": "2022-01-09T11:17:56.836298Z"
    }
   },
   "outputs": [],
   "source": [
    "def decoded_sequence(input_seq):\n",
    "    encoder_out, encoder_a, encoder_c = encoder_model.predict(input_seq) #Collecting output from encoder inference model.\n",
    "    #Initialise input to decoder neuron with START token. Thereafter output token predicted by each neuron will be used as input for the subsequent.\n",
    "    #Single elt matrix used for maintaining dimensions.\n",
    "    next_input = np.zeros((1,1))\n",
    "    next_input[0,0] = headline_tokenizer.word_index['start']\n",
    "    output_seq = ''\n",
    "    #Stopping condition to terminate loop when one summary is generated.\n",
    "    stop = False\n",
    "    while not stop:\n",
    "        #Output from decoder inference model, with output states of encoder used for initialisation.\n",
    "        decoded_out, trans_state_a, trans_state_c = decoder_model.predict([next_input] + [encoder_out, encoder_a, encoder_c])\n",
    "        #Get index of output token from y(t) of decoder.\n",
    "        output_idx = np.argmax(decoded_out[0, -1, :])\n",
    "        print(output_idx)\n",
    "        #If output index corresponds to END token, summary is terminated without of course adding the END token itself.\n",
    "        if output_idx == headline_tokenizer.word_index['end']:\n",
    "          # print(\"end detected.\")\n",
    "          stop = True\n",
    "\n",
    "        if output_idx>0 and output_idx != headline_tokenizer.word_index['start'] :\n",
    "            output_token = headline_tokenizer.index_word[output_idx] #Generate the token from index.\n",
    "            output_seq = output_seq + ' ' + output_token #Append to summary\n",
    "            out_length = len(output_seq)\n",
    "\n",
    "#             if int(out_length) > 10:\n",
    "#               print(\"hello\")\n",
    "#               stop = True\n",
    "\n",
    "        #Pass the current output index as input to next neuron.\n",
    "        next_input[0,0] = output_idx\n",
    "        #Continously update the transient state vectors in decoder.\n",
    "        encoder_a, encoder_c = trans_state_a, trans_state_c\n",
    "        \n",
    "    return output_seq   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T11:17:58.402380Z",
     "iopub.status.busy": "2022-01-09T11:17:58.401943Z",
     "iopub.status.idle": "2022-01-09T11:17:58.408038Z",
     "shell.execute_reply": "2022-01-09T11:17:58.407496Z",
     "shell.execute_reply.started": "2022-01-09T11:17:58.402348Z"
    }
   },
   "outputs": [],
   "source": [
    "headline_tokenizer.index_word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T11:18:23.175736Z",
     "iopub.status.busy": "2022-01-09T11:18:23.175434Z",
     "iopub.status.idle": "2022-01-09T11:18:24.040992Z",
     "shell.execute_reply": "2022-01-09T11:18:24.040293Z",
     "shell.execute_reply.started": "2022-01-09T11:18:23.175702Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 30\n",
    "print('News:', X_train.iloc[i])\n",
    "print('Actual Headline:', y_train.iloc[i])\n",
    "print('Predicted Headline:', decoded_sequence(x_train_pad[i].reshape(1, max_len_news)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
